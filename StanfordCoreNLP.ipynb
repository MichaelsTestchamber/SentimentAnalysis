{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Collecting stanfordcorenlp\n  Downloading https://files.pythonhosted.org/packages/35/cb/0a271890bbe3a77fc1aca2bc3a58b14e11799ea77cb5f7d6fb0a8b4c46fa/stanfordcorenlp-3.9.1.1-py2.py3-none-any.whl\nRequirement already satisfied: psutil in c:\\users\\micha\\anaconda3\\lib\\site-packages (from stanfordcorenlp) (5.6.3)\nRequirement already satisfied: requests in c:\\users\\micha\\anaconda3\\lib\\site-packages (from stanfordcorenlp) (2.22.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\micha\\anaconda3\\lib\\site-packages (from requests->stanfordcorenlp) (1.24.2)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\micha\\anaconda3\\lib\\site-packages (from requests->stanfordcorenlp) (2019.9.11)\nRequirement already satisfied: idna<2.9,>=2.5 in c:\\users\\micha\\anaconda3\\lib\\site-packages (from requests->stanfordcorenlp) (2.8)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\micha\\anaconda3\\lib\\site-packages (from requests->stanfordcorenlp) (3.0.4)\nInstalling collected packages: stanfordcorenlp\nSuccessfully installed stanfordcorenlp-3.9.1.1\nNote: you may need to restart the kernel to use updated packages.\n"
    }
   ],
   "source": [
    "#pip install stanfordcorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import logging\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-067d407ef11e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mStanfordNLP\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'http://localhost'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         self.nlp = StanfordCoreNLP(host, port=port,\n\u001b[0;32m      4\u001b[0m                                    timeout=30000)  # , quiet=False, logging_level=logging.DEBUG)\n\u001b[0;32m      5\u001b[0m         self.props = {\n",
      "\u001b[1;32m<ipython-input-5-067d407ef11e>\u001b[0m in \u001b[0;36mStanfordNLP\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m#if __name__ == '__main__':\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0msNLP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStanfordNLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'A blog post using Stanford CoreNLP Server. Visit www.khalidalnajjar.com for more details.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Annotate:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msNLP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e28e84b7a6f0>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, host, port)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'http://localhost'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         self.nlp = StanfordCoreNLP(host, port=port,\n\u001b[1;32m----> 4\u001b[1;33m                                    timeout=30000)  # , quiet=False, logging_level=logging.DEBUG)\n\u001b[0m\u001b[0;32m      5\u001b[0m         self.props = {\n\u001b[0;32m      6\u001b[0m             \u001b[1;34m'annotators'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'tokenize,ssplit,pos,lemma,ner,parse,depparse,dcoref,relation'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\stanfordcorenlp\\corenlp.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_host, port, memory, lang, timeout, quiet, logging_level)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mhost_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhostname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# OSX, not tested\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[1;32mwhile\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect_ex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Waiting until the server is available.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class StanfordNLP:\n",
    "    def __init__(self, host='http://localhost', port=9000):\n",
    "        self.nlp = StanfordCoreNLP(host, port=port,\n",
    "                                   timeout=30000)  # , quiet=False, logging_level=logging.DEBUG)\n",
    "        self.props = {\n",
    "            'annotators': 'tokenize,ssplit,pos,lemma,ner,parse,depparse,dcoref,relation',\n",
    "            'pipelineLanguage': 'en',\n",
    "            'outputFormat': 'json'\n",
    "        }\n",
    "\n",
    "    def word_tokenize(self, sentence):\n",
    "        return self.nlp.word_tokenize(sentence)\n",
    "\n",
    "    def pos(self, sentence):\n",
    "        return self.nlp.pos_tag(sentence)\n",
    "\n",
    "    def ner(self, sentence):\n",
    "        return self.nlp.ner(sentence)\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        return self.nlp.parse(sentence)\n",
    "\n",
    "    def dependency_parse(self, sentence):\n",
    "        return self.nlp.dependency_parse(sentence)\n",
    "\n",
    "    def annotate(self, sentence):\n",
    "        return json.loads(self.nlp.annotate(sentence, properties=self.props))\n",
    "\n",
    "    @staticmethod\n",
    "    def tokens_to_dict(_tokens):\n",
    "        tokens = defaultdict(dict)\n",
    "        for token in _tokens:\n",
    "            tokens[int(token['index'])] = {\n",
    "                'word': token['word'],\n",
    "                'lemma': token['lemma'],\n",
    "                'pos': token['pos'],\n",
    "                'ner': token['ner']\n",
    "            }\n",
    "        return tokens\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    sNLP = StanfordNLP()\n",
    "    text = 'A blog post using Stanford CoreNLP Server. Visit www.khalidalnajjar.com for more details.'\n",
    "    print (\"Annotate:\", sNLP.annotate(text))\n",
    "    print (\"POS:\", sNLP.pos(text))\n",
    "    print (\"Tokens:\", sNLP.word_tokenize(text))\n",
    "    print (\"NER:\", sNLP.ner(text))\n",
    "    print (\"Parse:\", sNLP.parse(text))\n",
    "    print (\"Dep Parse:\", sNLP.dependency_parse(text))\n",
    "    sNLP.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-a56d7dec7707>, line 4)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-a56d7dec7707>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    print 'Tokenize:', nlp.word_tokenize(sentence)\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "nlp = StanfordCoreNLP(r'G:\\JavaLibraries\\stanford-corenlp-full-2018-02-27')\n",
    "\n",
    "sentence = 'Guangdong University of Foreign Studies is located in Guangzhou.'\n",
    "print ('Tokenize:', nlp.word_tokenize(sentence))\n",
    "print ('Part of Speech:', nlp.pos_tag(sentence))\n",
    "print ('Named Entities:', nlp.ner(sentence))\n",
    "print ('Constituency Parsing:', nlp.parse(sentence))\n",
    "print ('Dependency Parsing:', nlp.dependency_parse(sentence))\n",
    "\n",
    "nlp.close() # Do not forget to close! The backend server will consume a lot memery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}